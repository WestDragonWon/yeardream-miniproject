apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  template:
    metadata:
      labels:
        app: airflow-scheduler
    spec:
      nodeSelector:
        type: worker  # worker 노드에만 배포
      initContainers:
        - name: initialize-airflow-db
          image: apache/airflow:2.9.3-python3.8
          command: ["airflow", "db", "init"]  # 데이터베이스 초기화
          env:
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://airflow:airflow@postgres:5432/airflow"
      containers:
        - name: airflow-scheduler
          image: apache/airflow:2.9.3-python3.8
          command: ["airflow", "scheduler"]
          env:
            - name: AIRFLOW__CORE__EXECUTOR
              value: "CeleryExecutor"
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://airflow:airflow@postgres:5432/airflow"
            - name: AIRFLOW__CELERY__BROKER_URL
              value: "redis://redis-cluster:6379/0"
          volumeMounts:
            - name: airflow-logs
              mountPath: /opt/airflow/logs  # 로그 마운트
            - name: airflow-dags
              mountPath: /opt/airflow/dags  # DAG 디렉토리 마운트
          readinessProbe:
            exec:
              command: ["airflow", "jobs", "check", "--job-type", "SchedulerJob"]
            initialDelaySeconds: 60
            periodSeconds: 20
            timeoutSeconds: 10
          livenessProbe:
            exec:
              command: ["airflow", "jobs", "check", "--job-type", "SchedulerJob"]
            initialDelaySeconds: 60
            periodSeconds: 20
            timeoutSeconds: 10
      volumes:
        - name: airflow-logs
          persistentVolumeClaim:
            claimName: airflow-logs-pvc
        - name: airflow-dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc  # DAG PVC 추가
      restartPolicy: Always
